# app.py
# =====================================
# ë¼ì´ë¸ŒëŸ¬ë¦¬
# =====================================
import io, os, glob, urllib.request, tempfile
import numpy as np
import pandas as pd
import streamlit as st

# ---- Matplotlib ìºì‹œ ê²½ë¡œ(ê¶Œí•œ ë¬¸ì œ íšŒí”¼) ----
os.environ["MPLCONFIGDIR"] = os.path.join(tempfile.gettempdir(), "mplconfig")
os.makedirs(os.environ["MPLCONFIGDIR"], exist_ok=True)

import matplotlib as mpl
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from matplotlib.ticker import StrMethodFormatter

from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import r2_score, mean_squared_error
import lightgbm as lgb

# =====================================
# ğŸ”¤ í•œê¸€ í°íŠ¸: ë¡œì»¬ ìš°ì„  + ìë™ ë‹¤ìš´ë¡œë“œ + Matplotlib + (ì˜µì…˜)ì›¹í°íŠ¸
# =====================================
FONT_URLS = [
    "https://raw.githubusercontent.com/notofonts/noto-cjk/main/Sans/OTF/Korean/NotoSansKR-Regular.otf",
    "https://github.com/notofonts/noto-cjk/raw/main/Sans/OTF/Korean/NotoSansKR-Regular.otf",
    "https://cdn.jsdelivr.net/gh/notofonts/noto-cjk@main/Sans/OTF/Korean/NotoSansKR-Regular.otf",
]
LOCAL_FONT_CANDIDATES = [
    "fonts/NotoSansKR-Regular.otf",
    "fonts/NanumGothic.ttf",
    "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
    "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
    "/System/Library/Fonts/AppleGothic.ttf",
    "C:/Windows/Fonts/malgun.ttf",
]

def _download_font_to_tmp() -> str | None:
    font_dir = os.path.join(tempfile.gettempdir(), "fonts")
    os.makedirs(font_dir, exist_ok=True)
    for url in FONT_URLS:
        try:
            local = os.path.join(font_dir, os.path.basename(url))
            urllib.request.urlretrieve(url, local)
            return local
        except Exception:
            continue
    return None

def apply_korean_font() -> tuple[str | None, str | None]:
    """
    ë°˜í™˜: (font_name, font_path_or_None)
    1) ë¡œì»¬/ì‹œìŠ¤í…œ â†’ 2) ë‹¤ìš´ë¡œë“œ â†’ 3) ì‹œìŠ¤í…œ ì´ë¦„ë§Œ ì§€ì •
    """
    # 1) ë¡œì»¬/ì‹œìŠ¤í…œ íŒŒì¼ ê²½ë¡œ
    for p in LOCAL_FONT_CANDIDATES:
        if os.path.exists(p):
            try:
                fm.fontManager.addfont(p)
                try:
                    fm._load_fontmanager(try_read_cache=False)
                except Exception:
                    fm._rebuild()
                name = fm.FontProperties(fname=p).get_name()
                mpl.rcParams["font.family"] = name
                mpl.rcParams["font.sans-serif"] = [name]
                mpl.rcParams["axes.unicode_minus"] = False
                mpl.rcParams["pdf.fonttype"] = 42
                mpl.rcParams["ps.fonttype"] = 42
                return name, p
            except Exception:
                pass

    # 2) ë‹¤ìš´ë¡œë“œ
    path = _download_font_to_tmp()
    if path and os.path.exists(path):
        try:
            fm.fontManager.addfont(path)
            try:
                fm._load_fontmanager(try_read_cache=False)
            except Exception:
                fm._rebuild()
            name = fm.FontProperties(fname=path).get_name()
            mpl.rcParams["font.family"] = name
            mpl.rcParams["font.sans-serif"] = [name]
            mpl.rcParams["axes.unicode_minus"] = False
            mpl.rcParams["pdf.fonttype"] = 42
            mpl.rcParams["ps.fonttype"] = 42
            # UI í…ìŠ¤íŠ¸ë„ ë§ì¶”ê³  ì‹¶ìœ¼ë©´ CSS ì£¼ì…
            st.markdown(
                f"<style>html, body, [class*='css'] {{ font-family: '{name}', sans-serif !important; }}</style>",
                unsafe_allow_html=True,
            )
            return name, path
        except Exception:
            pass

    # 3) ìµœí›„: ì‹œìŠ¤í…œì— ë“±ë¡ëœ ì´ë¦„ë§Œ
    for nm in ["Noto Sans CJK KR", "Noto Sans KR", "NanumGothic", "Malgun Gothic", "AppleGothic"]:
        if any(f.name == nm for f in fm.fontManager.ttflist):
            mpl.rcParams["font.family"] = nm
            mpl.rcParams["font.sans-serif"] = [nm]
            mpl.rcParams["axes.unicode_minus"] = False
            return nm, None

    return None, None

KOREAN_FONT_NAME, KOREAN_FONT_PATH = apply_korean_font()

# âœ… ì—¬ê¸°ë§Œ ë°”ë€œ: ë¬¸ìì—´ family ëŒ€ì‹  ë¦¬ìŠ¤íŠ¸/ê¸°ë³¸ê°’ ì‚¬ìš©
if KOREAN_FONT_PATH:
    LEGEND_PROP = fm.FontProperties(fname=KOREAN_FONT_PATH)
elif KOREAN_FONT_NAME:
    LEGEND_PROP = fm.FontProperties(family=[KOREAN_FONT_NAME])  # ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬
else:
    LEGEND_PROP = fm.FontProperties()  # rcParams ê¸°ë³¸

# =====================================
# âš™ï¸ ìœ í‹¸
# =====================================
REQUIRED_ACTUAL = ["ë‚ ì§œ", "í‰ê· ê¸°ì˜¨", "ê³µê¸‰ëŸ‰"]
REQUIRED_SCENARIO = ["ì‹œë‚˜ë¦¬ì˜¤", "ì›”", "í‰ê· ê¸°ì˜¨"]

def fit_one_model(model_name, base_model, X, y):
    if model_name == "3ì°¨ ë‹¤í•­íšŒê·€":
        poly = PolynomialFeatures(degree=3)
        X_poly = poly.fit_transform(X)
        model = base_model
        model.fit(X_poly, y)
        return model, poly
    else:
        model = base_model
        model.fit(X, y)
        return model, None

def predict_with(model_name, model, poly, X_new_2d):
    if model_name == "3ì°¨ ë‹¤í•­íšŒê·€":
        return model.predict(poly.transform(X_new_2d))
    else:
        return model.predict(X_new_2d)

def calc_metrics(y_true, y_pred):
    r2 = r2_score(y_true, y_pred) if len(y_true) > 1 else np.nan
    rmse = np.sqrt(mean_squared_error(y_true, y_pred)) if len(y_true) > 0 else np.nan
    mape = (np.mean(np.abs((y_true - y_pred) / y_true)) * 100.0) if np.all(y_true != 0) else np.nan
    return r2, rmse, mape

def scenario_exists_for_year(scenario_df, year):
    return str(int(year)) in scenario_df["ì‹œë‚˜ë¦¬ì˜¤"].astype(str).unique()

# ---- ìˆ«ì í¬ë§·(ì§€ìˆ˜í‘œê¸° ê¸ˆì§€) ----
def _fmt_num(x: float) -> str:
    ax = abs(x)
    if ax >= 1e9: return f"{x:,.0f}"
    if ax >= 1e6: return f"{x:,.1f}"
    if ax >= 1e3: return f"{x:,.2f}"
    if ax >= 1:   return f"{x:,.3f}"
    s = f"{x:.6f}".rstrip("0").rstrip(".")
    return s if s else "0"

def _signed(term: float, label: str | None) -> str:
    sign = "-" if term < 0 else "+"
    core = f"{_fmt_num(abs(term))}"
    return f"{sign} {core}{('Â·'+label) if label else ''}"

def format_poly_equation(model, poly):
    if (model is None) or (poly is None):
        return None
    coefs = np.ravel(model.coef_)
    intercept = float(getattr(model, "intercept_", 0.0))
    include_bias = bool(poly.get_params().get("include_bias", True))
    if include_bias:
        a0 = intercept + (coefs[0] if len(coefs) > 0 else 0.0)
        a1 = coefs[1] if len(coefs) > 1 else 0.0
        a2 = coefs[2] if len(coefs) > 2 else 0.0
        a3 = coefs[3] if len(coefs) > 3 else 0.0
    else:
        a0 = intercept
        a1 = coefs[0] if len(coefs) > 0 else 0.0
        a2 = coefs[1] if len(coefs) > 1 else 0.0
        a3 = coefs[2] if len(coefs) > 2 else 0.0
    eq = f"3ì°¨ì‹: y = {_fmt_num(a3)}Â·xÂ³ {_signed(a2,'xÂ²')} {_signed(a1,'x')} {_signed(a0,None)}".rstrip()
    return eq

def validate_columns(df, required, label):
    missing = [c for c in required if c not in df.columns]
    if missing:
        st.error(f"[{label}] í•„ìš”í•œ ì»¬ëŸ¼ {required} ì¤‘ ëˆ„ë½: {missing}\n\ní˜„ì¬ ì»¬ëŸ¼: {list(df.columns)}")
        st.stop()

def _read_any(src):
    def _try_csv(bio):
        for enc in ("cp949", "utf-8-sig", "utf-8"):
            try:
                return pd.read_csv(bio, encoding=enc)
            except Exception:
                bio.seek(0)
        raise
    if hasattr(src, "read") or isinstance(src, (bytes, bytearray)):
        bio = io.BytesIO(src if isinstance(src, (bytes, bytearray)) else src.read())
        try:
            bio.seek(0)
            return pd.read_excel(bio)
        except Exception:
            pass
        bio.seek(0)
        return _try_csv(bio)
    ext = os.path.splitext(str(src))[1].lower()
    if ext in (".xlsx", ".xls"):
        return pd.read_excel(src)
    else:
        for enc in ("cp949", "utf-8-sig", "utf-8"):
            try:
                return pd.read_csv(src, encoding=enc)
            except Exception:
                continue
        return pd.read_csv(src)

@st.cache_data
def load_data_mixed(actual_src, scenario_src, is_upload: bool):
    actual_df = _read_any(actual_src)
    scenario_df = _read_any(scenario_src)
    validate_columns(actual_df, REQUIRED_ACTUAL, "ì‹¤ì  íŒŒì¼")
    validate_columns(scenario_df, REQUIRED_SCENARIO, "ì‹œë‚˜ë¦¬ì˜¤ íŒŒì¼")

    data = actual_df[["ë‚ ì§œ", "í‰ê· ê¸°ì˜¨", "ê³µê¸‰ëŸ‰"]].copy()
    data["ë‚ ì§œ"] = pd.to_datetime(data["ë‚ ì§œ"])
    data["Year"] = data["ë‚ ì§œ"].dt.year.astype(int)
    data["Month"] = data["ë‚ ì§œ"].dt.month.astype(int)

    scenario = scenario_df[["ì‹œë‚˜ë¦¬ì˜¤", "ì›”", "í‰ê· ê¸°ì˜¨"]].copy()
    scenario["ì›”"] = scenario["ì›”"].astype(int)
    scenario["ì‹œë‚˜ë¦¬ì˜¤"] = scenario["ì‹œë‚˜ë¦¬ì˜¤"].astype(str)
    return data, scenario

# ========= í‘œ ìˆ«ì í¬ë§·(ì²œë‹¨ìœ„ ì½¤ë§ˆ) ìœ í‹¸ =========
def style_thousands(df: pd.DataFrame, digits: int = 0):
    """
    ëª¨ë“  ìˆ«ìí˜• ì»¬ëŸ¼ì„ ì²œë‹¨ìœ„ ì½¤ë§ˆë¡œ í‘œì‹œ.
    digitsëŠ” ë°˜ì˜¬ë¦¼ ì†Œìˆ˜ ìë¦¿ìˆ˜(0ì´ë©´ ì •ìˆ˜ë¡œ ë°˜ì˜¬ë¦¼).
    """
    fmt: dict[str, str] = {}
    digs = max(int(digits), 0)
    for c in df.columns:
        if pd.api.types.is_numeric_dtype(df[c]):
            fmt[c] = f"{{:,.{digs}f}}"  # 0ì´ë©´ ì •ìˆ˜
    sty = df.style.format(fmt)
    if hasattr(sty, "hide_index"):
        sty = sty.hide_index()
    else:
        try:
            sty = sty.hide(axis="index")
        except Exception:
            pass
    return sty

# =====================================
# ğŸ–¥ï¸ Streamlit UI
# =====================================
st.set_page_config(page_title="ë„ì‹œê°€ìŠ¤ ê³µê¸‰ëŸ‰ ì˜ˆì¸¡/ê²€ì¦", layout="wide")
st.title("ë„ì‹œê°€ìŠ¤ ê³µê¸‰ëŸ‰ ì˜ˆì¸¡ Â· ê²€ì¦ ëŒ€ì‹œë³´ë“œ")
st.caption(f"í•œê¸€ í°íŠ¸: {KOREAN_FONT_NAME or 'ë¯¸ì ìš©'}{' (íŒŒì¼ ê²½ë¡œ ì ìš©)' if KOREAN_FONT_PATH else ''}")

DEFAULT_ACTUAL_PATH = "data/ì‹¤ì .xlsx"
DEFAULT_SCENARIO_PATH = "data/ê¸°ì˜¨ì‹œë‚˜ë¦¬ì˜¤.xlsx"

with st.sidebar:
    st.header("ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë°©ì‹")
    mode = st.radio("ë°©ì‹ ì„ íƒ", ["Repo ë‚´ íŒŒì¼ ì‚¬ìš©", "íŒŒì¼ ì—…ë¡œë“œ"], index=0)

    if mode == "Repo ë‚´ íŒŒì¼ ì‚¬ìš©":
        repo_actual = sorted(glob.glob("data/*.xlsx") + glob.glob("data/*.xls"))
        repo_scn = sorted(set(glob.glob("data/*.csv") + glob.glob("data/*.xlsx") + glob.glob("data/*.xls")))

        def pick_idx(options, target):
            try:
                return options.index(target)
            except ValueError:
                return 0 if options else 0

        if not repo_actual:
            st.error("data í´ë”ì— ì‹¤ì  ì—‘ì…€ íŒŒì¼ì´ ì—†ë„¤. ì—…ë¡œë“œ ëª¨ë“œë¡œ ì“°ë©´ ë¼.")
            st.stop()
        if not repo_scn:
            st.error("data í´ë”ì— ì‹œë‚˜ë¦¬ì˜¤ íŒŒì¼ì´ ì—†ë„¤. data/ê¸°ì˜¨ì‹œë‚˜ë¦¬ì˜¤.xlsx ë˜ëŠ” .csv ë„£ìœ¼ë©´ ë¼.")
            st.stop()

        actual_path = st.selectbox("ì‹¤ì  íŒŒì¼(Excel)", options=repo_actual, index=pick_idx(repo_actual, DEFAULT_ACTUAL_PATH), key="actual_path")
        sc_path = st.selectbox("ì‹œë‚˜ë¦¬ì˜¤ íŒŒì¼(CSV/Excel)", options=repo_scn, index=pick_idx(repo_scn, DEFAULT_SCENARIO_PATH), key="sc_path")
        data_input_ready = True
    else:
        st.header("ë°ì´í„° ì—…ë¡œë“œ")
        data_file = st.file_uploader("ì‹¤ì  ì—‘ì…€ ì—…ë¡œë“œ(.xlsx/.xls)", type=["xlsx", "xls"], key="up_actual")
        sc_file = st.file_uploader("ì‹œë‚˜ë¦¬ì˜¤ ì—…ë¡œë“œ(CSV/Excel)", type=["csv", "xlsx", "xls"], key="up_scn")
        st.caption("â€» ì‹¤ì  íŒŒì¼ ì—´: **ë‚ ì§œ / í‰ê· ê¸°ì˜¨ / ê³µê¸‰ëŸ‰** Â· ì‹œë‚˜ë¦¬ì˜¤ ì—´: **ì‹œë‚˜ë¦¬ì˜¤ / ì›” / í‰ê· ê¸°ì˜¨** (ì‹œë‚˜ë¦¬ì˜¤ ê°’=ì—°ë„)")
        data_input_ready = (data_file is not None) and (sc_file is not None)

if not data_input_ready:
    st.info("ì™¼ìª½ì—ì„œ íŒŒì¼ì„ ì„ íƒ(ë˜ëŠ” ì—…ë¡œë“œ)í•˜ë©´ ë°”ë¡œ ì²˜ë¦¬í• ê²Œ.")
    st.stop()

# ===== ë°ì´í„° ë¡œë“œ =====
if mode == "Repo ë‚´ íŒŒì¼ ì‚¬ìš©":
    data, scenario_data = load_data_mixed(st.session_state["actual_path"], st.session_state["sc_path"], is_upload=False)
else:
    data, scenario_data = load_data_mixed(st.session_state["up_actual"], st.session_state["up_scn"], is_upload=True)

min_year, max_year = int(data["Year"].min()), int(data["Year"].max())
current_year = pd.Timestamp.today().year

# ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì—°ë„ í’€: (ì‹¤ì  ì²«í•´+1) ~ max(ì‹¤ì  ë§ˆì§€ë§‰+3, í˜„ì¬+3)
fy_min = min_year + 1
fy_max = max(max_year + 3, current_year + 3)
fy_options = list(range(fy_min, fy_max + 1))

# ê¸°ë³¸ From/To: From = ì‹¤ì  ë§ˆì§€ë§‰+1, To = min(From+3, fy_max)
fy_from_default = min(max_year + 1, fy_max)
fy_to_default = min(fy_from_default + 3, fy_max)

models = {
    "3ì°¨ ë‹¤í•­íšŒê·€": LinearRegression(),
    "ëœë¤í¬ë ˆìŠ¤íŠ¸": RandomForestRegressor(random_state=42),
    "ê·¸ë ˆì´ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…": GradientBoostingRegressor(random_state=42),
    "ì•„ë‹¤ë¶€ìŠ¤íŠ¸": AdaBoostRegressor(random_state=42),
    "LGBM": lgb.LGBMRegressor(random_state=42),
    "ìµœê·¼ì ‘ì´ì›ƒ": KNeighborsRegressor(),
}

# ===== ì„¤ì •: í¼ìœ¼ë¡œ ë¬¶ì–´ì„œ 'ê³µê¸‰ëŸ‰ ì˜ˆì¸¡ ì‹¤í–‰' ëˆŒëŸ¬ì•¼ ë°˜ì˜ =====
with st.sidebar:
    st.header("ì˜ˆì¸¡/ê²€ì¦ ì„¤ì •")
    with st.form("run_form", clear_on_submit=False):
        st.caption("ì˜ˆì¸¡ì—°ë„ëŠ” From~To(ìµœëŒ€ 3ë…„ í­). ê°’ ë°”ê¾¸ê³  **ê³µê¸‰ëŸ‰ ì˜ˆì¸¡ ì‹¤í–‰**ì„ ëˆŒëŸ¬ ë°˜ì˜ë¼.")
        fy_from = st.selectbox("ì˜ˆì¸¡ì—°ë„ From", options=fy_options, index=fy_options.index(fy_from_default), key="fy_from")
        to_candidates = [y for y in fy_options if fy_from <= y <= min(fy_from + 3, fy_max)]
        fy_to = st.selectbox("ì˜ˆì¸¡ì—°ë„ To (â‰¤ From+3)", options=to_candidates, index=len(to_candidates)-1 if fy_to_default not in to_candidates else to_candidates.index(fy_to_default), key="fy_to")

        # í•™ìŠµ ì¢…ë£ŒëŠ” From-1ì„ ë„˜ì§€ ì•Šë„ë¡
        end_cap = min(max_year, fy_from - 1)
        tr_start = st.slider("í•™ìŠµ ì‹œì‘ì—°ë„", min_year, end_cap, max(min_year, end_cap-4), key="tr_start")
        tr_end = st.slider("í•™ìŠµ ì¢…ë£Œì—°ë„(â‰¤From-1)", tr_start, end_cap, end_cap, key="tr_end")

        m1, m2 = st.slider("ì›” ë²”ìœ„", 1, 12, (1, 12), key="mrange")
        sel_models = st.multiselect("ëª¨ë¸ ì„ íƒ", list(models.keys()), default=list(models.keys()), key="sel_models")

        show_avg = st.checkbox("ì˜ˆì¸¡ì˜ì—­ì— ì‹¤ì (ì›”í‰ê· ) ë³´ì¡°ì„ ", value=False, key="show_avg")
        show_tbl = st.checkbox("í‘œ ë³´ê¸°", value=True, key="show_tbl")

        st.markdown("---")
        want_excel = st.checkbox("ì—‘ì…€ë¡œ ê²°ê³¼ ì €ì¥", key="want_excel")
        out_name = st.text_input("ì—‘ì…€ íŒŒì¼ëª…", "forecast_backtest_report.xlsx", key="out_name")

        run_clicked = st.form_submit_button("ê³µê¸‰ëŸ‰ ì˜ˆì¸¡ ì‹¤í–‰", use_container_width=True, type="primary")

if "init_run_done" not in st.session_state:
    run_clicked = True
    st.session_state["init_run_done"] = True

# ===== ê³µí†µ ì²´í¬ =====
if len(st.session_state["sel_models"]) == 0:
    st.warning("ëª¨ë¸ì„ 1ê°œ ì´ìƒ ì„ íƒí•´ì¤˜.")
    st.stop()

# ===== ì‹¤í–‰ =====
if run_clicked:
    fy_from = st.session_state["fy_from"]
    fy_to = st.session_state["fy_to"]
    year_list = [y for y in fy_options if fy_from <= y <= fy_to]

    train_start = st.session_state["tr_start"]
    train_end = st.session_state["tr_end"]
    (m1, m2) = st.session_state["mrange"]
    sel_models = st.session_state["sel_models"]
    show_avg = st.session_state["show_avg"]
    show_tables = st.session_state["show_tbl"]
    want_excel = st.session_state["want_excel"]
    out_name = st.session_state["out_name"]

    # ===== í•™ìŠµ & ì˜ˆì¸¡ ê³µí†µ ì¤€ë¹„ =====
    train_pred = data[(data["Year"] >= train_start) & (data["Year"] <= train_end)].dropna(subset=["ê³µê¸‰ëŸ‰"])
    Xp, yp = train_pred[["í‰ê· ê¸°ì˜¨"]].values, train_pred["ê³µê¸‰ëŸ‰"].values

    trained_pred, r2_train_pred = {}, {}
    for name in sel_models:
        base = models[name]
        if name == "ìµœê·¼ì ‘ì´ì›ƒ":
            n_neighbors = getattr(base, "n_neighbors", 5)
            if len(train_pred) < n_neighbors:
                st.info(f"[ì˜ˆì¸¡ SKIP] {name}: í‘œë³¸ {len(train_pred)} < n_neighbors {n_neighbors}")
                continue
        mdl, poly = fit_one_model(name, base, Xp, yp)
        trained_pred[name] = (mdl, poly)
        r2_train_pred[name] = r2_score(yp, predict_with(name, mdl, poly, Xp)) if len(yp) > 1 else np.nan

    if len(trained_pred) == 0:
        st.error("ì˜ˆì¸¡ìš© í•™ìŠµì— ì„±ê³µí•œ ëª¨ë¸ì´ ì—†ì–´.")
        st.stop()

    excel_buf = io.BytesIO()
    writer = pd.ExcelWriter(excel_buf, engine="openpyxl") if want_excel else None

    # ===== ì—°ë„ë³„ ì˜ˆì¸¡(ê·¸ë˜í”„/í‘œ) =====
    for fy in year_list:
        if not scenario_exists_for_year(scenario_data, fy):
            st.warning(f"[ì˜ˆì¸¡ {fy}] ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°ê°€ ì—†ì–´. ê±´ë„ˆë›¸ê²Œ.")
            continue

        # ì„ íƒ ì›” ë²”ìœ„ ë°ì´í„°
        sdata = scenario_data[(scenario_data["ì›”"] >= m1) & (scenario_data["ì›”"] <= m2)]
        sdata = sdata[sdata["ì‹œë‚˜ë¦¬ì˜¤"].astype(str) == str(fy)]

        # ì „ì²´ 1~12ì›” ë°ì´í„°(ì†Œê³„ ê³„ì‚°ìš©)
        sdata_full = scenario_data[scenario_data["ì‹œë‚˜ë¦¬ì˜¤"].astype(str) == str(fy)].copy()
        sdata_full = sdata_full[(sdata_full["ì›”"] >= 1) & (sdata_full["ì›”"] <= 12)]

        # ---- ì˜ˆì¸¡(ì„ íƒ ì›”)
        preds_rows = []
        for name, (mdl, poly) in trained_pred.items():
            for _, row in sdata.iterrows():
                yhat = float(predict_with(name, mdl, poly, np.array([[float(row["í‰ê· ê¸°ì˜¨"])]]))[0])
                preds_rows.append([int(row["ì›”"]), str(fy), float(row["í‰ê· ê¸°ì˜¨"]), name, f"{train_start}~{train_end}", int(fy), yhat])
        preds_forecast = pd.DataFrame(
            preds_rows,
            columns=["Month","ê¸°ì˜¨ì‹œë‚˜ë¦¬ì˜¤","í‰ê· ê¸°ì˜¨","Model","í•™ìŠµê¸°ê°„","ì˜ˆì¸¡ì—°ë„","ì˜ˆì¸¡ê³µê¸‰ëŸ‰"]
        )

        # ---- ì˜ˆì¸¡(ì—°ê°„ ì†Œê³„ìš©: 1~12ì›”)
        preds_rows_full = []
        for name, (mdl, poly) in trained_pred.items():
            for _, row in sdata_full.iterrows():
                yhat = float(predict_with(name, mdl, poly, np.array([[float(row["í‰ê· ê¸°ì˜¨"])]]))[0])
                preds_rows_full.append([int(row["ì›”"]), str(fy), float(row["í‰ê· ê¸°ì˜¨"]), name, int(fy), yhat])
        preds_full = pd.DataFrame(preds_rows_full, columns=["Month","ê¸°ì˜¨ì‹œë‚˜ë¦¬ì˜¤","í‰ê· ê¸°ì˜¨","Model","ì˜ˆì¸¡ì—°ë„","ì˜ˆì¸¡ê³µê¸‰ëŸ‰"])

        # ---- ê·¸ë˜í”„
        fig, ax = plt.subplots(figsize=(11,5))
        for name, grp in preds_forecast.groupby("Model"):
            g = grp.sort_values("Month")
            ax.plot(g["Month"], g["ì˜ˆì¸¡ê³µê¸‰ëŸ‰"], marker="o", linewidth=1.8, label=name)

        if show_avg:
            avg = data.groupby("Month", as_index=False)["ê³µê¸‰ëŸ‰"].mean().rename(columns={"ê³µê¸‰ëŸ‰":"ì‹¤ì (ì›”í‰ê· )"})
            avg = avg[(avg["Month"]>=m1)&(avg["Month"]<=m2)]
            ax.plot(avg["Month"], avg["ì‹¤ì (ì›”í‰ê· )"], linestyle="--", linewidth=2.2, label="ì‹¤ì (ì›”í‰ê· )")

        ax.set_title(f"[ì˜ˆì¸¡] ì˜ˆì¸¡ì—°ë„:{fy} / ì‹œë‚˜ë¦¬ì˜¤:{fy} / ì›” {m1}~{m2} / í•™ìŠµê¸°ê°„ {train_start}~{train_end}")
        ax.set_xlabel("ì›”"); ax.set_ylabel("ì˜ˆì¸¡ê³µê¸‰ëŸ‰")
        ax.grid(True, alpha=0.3); ax.set_xticks(range(m1, m2+1))
        ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))
        ax.legend(loc="best", fontsize=9, ncol=2, prop=LEGEND_PROP)

        if "3ì°¨ ë‹¤í•­íšŒê·€" in trained_pred:
            mdl, poly = trained_pred["3ì°¨ ë‹¤í•­íšŒê·€"]
            eq = format_poly_equation(mdl, poly)
            if eq:
                fig.subplots_adjust(bottom=0.18)
                r2t = r2_train_pred.get("3ì°¨ ë‹¤í•­íšŒê·€", np.nan)
                fig.text(0.5, 0.02, f"{eq} | í•™ìŠµ RÂ²={r2t:.3f}", ha="center", va="bottom", fontsize=10, fontproperties=LEGEND_PROP)

        st.pyplot(fig, use_container_width=True)

        # ---- í‘œ: í”¼ë²— + ì†Œê³„(1~12)
        if show_tables:
            st.subheader(f"ì˜ˆì¸¡ í”¼ë²— (Y={fy})")

            pv = preds_forecast.pivot_table(index="Month", columns="Model", values="ì˜ˆì¸¡ê³µê¸‰ëŸ‰", aggfunc="mean")
            totals = preds_full.groupby("Model")["ì˜ˆì¸¡ê³µê¸‰ëŸ‰"].sum().reindex(pv.columns)
            pv.loc["ì†Œê³„(1~12)"] = totals.values

            st.dataframe(style_thousands(pv.fillna(0).astype(float), digits=0), use_container_width=True)

            if want_excel and writer is not None:
                pv_to_xlsx = pv.copy()
                pv_to_xlsx.reset_index(names="Month").to_excel(writer, sheet_name=f"ì˜ˆì¸¡í”¼ë²—(Y={fy})", index=False)
                preds_forecast.to_excel(writer, sheet_name=f"ì˜ˆì¸¡(Y={fy})raw", index=False)

    # ===== ê²€ì¦(backtest): 'ì²«í•´ ê¸°ì¤€' í•œ ë²ˆë§Œ =====
    base_year = year_list[0]
    Ym1, Ym2 = (base_year - 1), (base_year - 2)
    train_bt_end = min(train_end, Ym2)

    if train_bt_end < train_start:
        st.info(f"[ê²€ì¦] ì²«í•´ ê¸°ì¤€(Y={base_year}) í•™ìŠµê¸°ê°„ì´ ì„±ë¦½í•˜ì§€ ì•Šì•„. (ì‹œì‘={train_start}, ì¢…ë£Œ={train_bt_end})")
    else:
        train_bt = data[(data["Year"]>=train_start)&(data["Year"]<=train_bt_end)].dropna(subset=["ê³µê¸‰ëŸ‰"])
        Xb, yb = train_bt[["í‰ê· ê¸°ì˜¨"]].values, train_bt["ê³µê¸‰ëŸ‰"].values

        trained_bt = {}
        for name in sel_models:
            base = models[name]
            if name == "ìµœê·¼ì ‘ì´ì›ƒ":
                n_neighbors = getattr(base, "n_neighbors", 5)
                if len(train_bt) < n_neighbors:
                    st.info(f"[ê²€ì¦ SKIP] {name}: í‘œë³¸ {len(train_bt)} < n_neighbors {n_neighbors}")
                    continue
            mdl, poly = fit_one_model(name, base, Xb, yb)
            trained_bt[name] = (mdl, poly)

        val_df = data[(data["Year"]==Ym1)&(data["Month"]>=m1)&(data["Month"]<=m2)].dropna(subset=["ê³µê¸‰ëŸ‰","í‰ê· ê¸°ì˜¨"])
        val_df_full = data[(data["Year"]==Ym1)&(data["Month"]>=1)&(data["Month"]<=12)].dropna(subset=["ê³µê¸‰ëŸ‰","í‰ê· ê¸°ì˜¨"])

        if val_df.empty:
            st.info(f"[ê²€ì¦] {Ym1}ë…„ ì‹¤ì œ ë°ì´í„°ê°€ ì—†ì–´.")
        else:
            X_val, y_val = val_df[["í‰ê· ê¸°ì˜¨"]].values, val_df["ê³µê¸‰ëŸ‰"].values

            rows, preds_all = [], []
            for name,(mdl,poly) in trained_bt.items():
                yhat = predict_with(name, mdl, poly, X_val)
                r2, rmse, mape = calc_metrics(y_val, yhat)
                tmp = val_df[["Year","Month"]].copy()
                tmp["Model"] = name
                tmp["ì‹¤ì œê³µê¸‰ëŸ‰"] = y_val
                tmp["ì˜ˆì¸¡ê³µê¸‰ëŸ‰"] = yhat
                preds_all.append(tmp)
                rows.append([name, r2, rmse, mape])

            preds_val_df = pd.concat(preds_all, ignore_index=True) if preds_all else pd.DataFrame()
            metrics_df = pd.DataFrame(rows, columns=["Model","R2(ê²€ì¦)","RMSE","MAPE(%)"]).sort_values("R2(ê²€ì¦)", ascending=False)

            fig2, ax2 = plt.subplots(figsize=(11,5))
            gv = val_df.sort_values("Month")
            ax2.plot(gv["Month"], gv["ê³µê¸‰ëŸ‰"], linestyle="--", marker="o", linewidth=3.0, label=f"ì‹¤ì œ {Ym1}")

            best_model = metrics_df.iloc[0]["Model"] if not metrics_df.empty else None
            for name in metrics_df["Model"] if not metrics_df.empty else []:
                gpred = preds_val_df[preds_val_df["Model"]==name].sort_values("Month")
                lw = 2.2 if name == best_model else 1.5
                r2v = metrics_df.loc[metrics_df["Model"]==name, "R2(ê²€ì¦)"].values[0]
                ax2.plot(gpred["Month"], gpred["ì˜ˆì¸¡ê³µê¸‰ëŸ‰"], marker="o", linewidth=lw, label=f"{name} (RÂ²={r2v:.3f})")

            ax2.set_title(f"[ê²€ì¦] ì²«í•´ ê¸°ì¤€ Y={base_year} â†’ ì‹¤ì œ {Ym1}(ì ì„ ) vs ì˜ˆì¸¡ (í•™ìŠµê¸°ê°„ {train_start}~{train_bt_end})")
            ax2.set_xlabel("ì›”"); ax2.set_ylabel("ê³µê¸‰ëŸ‰")
            ax2.grid(True, alpha=0.3); ax2.set_xticks(range(m1, m2+1))
            ax2.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))
            ax2.legend(loc="best", fontsize=9, ncol=2, prop=LEGEND_PROP)

            if "3ì°¨ ë‹¤í•­íšŒê·€" in trained_bt:
                mdl_bt, poly_bt = trained_bt["3ì°¨ ë‹¤í•­íšŒê·€"]
                eq_bt = format_poly_equation(mdl_bt, poly_bt)
                if eq_bt:
                    fig2.subplots_adjust(bottom=0.18)
                    s = metrics_df.loc[metrics_df["Model"]=="3ì°¨ ë‹¤í•­íšŒê·€","R2(ê²€ì¦)"]
                    r2_val = float(s.iloc[0]) if len(s)>0 else np.nan
                    fig2.text(0.5, 0.02, f"{eq_bt} | ê²€ì¦ RÂ²={r2_val:.3f}", ha="center", va="bottom", fontsize=10, fontproperties=LEGEND_PROP)

            st.pyplot(fig2, use_container_width=True)

            if show_tables:
                st.subheader(f"ê²€ì¦ ì„±ëŠ¥ ìš”ì•½ (ê¸°ì¤€ì—°ë„ Y={base_year})")
                st.dataframe(metrics_df.reset_index(drop=True).round(4), use_container_width=True)

                if not preds_val_df.empty:
                    merged = preds_val_df.merge(val_df[["Month","ê³µê¸‰ëŸ‰"]], on="Month", how="left", suffixes=("","_ì‹¤ì œ"))
                    pv_val = merged.pivot_table(index="Month", columns="Model", values="ì˜ˆì¸¡ê³µê¸‰ëŸ‰", aggfunc="mean")

                    preds_all_full_rows = []
                    for name,(mdl,poly) in trained_bt.items():
                        yhat_full = predict_with(name, mdl, poly, val_df_full[["í‰ê· ê¸°ì˜¨"]].values)
                        tmpf = pd.DataFrame({"Month": val_df_full["Month"].values, "Model": name, "ì˜ˆì¸¡ê³µê¸‰ëŸ‰": yhat_full})
                        preds_all_full_rows.append(tmpf)
                    preds_val_full = pd.concat(preds_all_full_rows, ignore_index=True) if preds_all_full_rows else pd.DataFrame()

                    pv_val["ì‹¤ì œ"] = val_df.set_index("Month")["ê³µê¸‰ëŸ‰"]
                    totals_pred = preds_val_full.groupby("Model")["ì˜ˆì¸¡ê³µê¸‰ëŸ‰"].sum() if not preds_val_full.empty else pd.Series(dtype=float)
                    totals_row = {col: totals_pred.get(col, np.nan) for col in pv_val.columns if col != "ì‹¤ì œ"}
                    totals_row["ì‹¤ì œ"] = val_df_full["ê³µê¸‰ëŸ‰"].sum() if not val_df_full.empty else np.nan
                    pv_val.loc["ì†Œê³„(1~12)"] = pd.Series(totals_row)

                    st.dataframe(style_thousands(pv_val.fillna(0).astype(float), digits=0), use_container_width=True)

                    if want_excel and writer is not None:
                        pv_val_to_xlsx = pv_val.copy().reset_index(names="Month")
                        pv_val_to_xlsx.to_excel(writer, sheet_name=f"ê²€ì¦í”¼ë²—({Ym1})", index=False)
                        metrics_df.to_excel(writer, sheet_name="ê²€ì¦ì„±ëŠ¥ìš”ì•½", index=False)

    # ===== ì—‘ì…€ ë‹¤ìš´ë¡œë“œ =====
    if want_excel and writer is not None:
        writer.close()
        st.download_button(
            "ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
            data=excel_buf.getvalue(),
            file_name=out_name,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
